{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2b3d5c-83c3-4e2a-9d09-ce0c53840d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfeb4037-96aa-4dab-ae33-ef3b09f4890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9357, 784) (4609, 784) (9357,) (4609,)\n",
      "(784, 9357) (784, 4609) (1, 9357) (1, 4609)\n"
     ]
    }
   ],
   "source": [
    "#Prepare training and test data\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load MNIST (first time takes a minute)\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# Convert y to string → integer\n",
    "y = y.astype(int)\n",
    "\n",
    "# Filter only 3s and 8s\n",
    "mask = (y == 3) | (y == 8)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Convert labels: 3 → 0, 8 → 1\n",
    "y = (y == 8).astype(int)\n",
    "\n",
    "# Split training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape , X_test.shape , y_train.shape , y_test.shape)\n",
    "\n",
    "# Transpose data\n",
    "\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "y_train = y_train.reshape(1, -1)\n",
    "y_test = y_test.reshape(1, -1)\n",
    "\n",
    "print(X_train.shape , X_test.shape , y_train.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a82c2d5-c477-4ad3-b4af-7081315dd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Sigmoid function and its derivative\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500) \n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0392d1d-2bbe-435e-a5a8-4cd65302f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize parameters \n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "\n",
    "    w1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "\n",
    "    w2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "\n",
    "    learning_rate = 0.5\n",
    "\n",
    "    return(w1, b1, w2, b2, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9abd929d-2d07-47bb-8238-04db74cae2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward propagation \n",
    "\n",
    "def forward_propagation(X, w1, b1, w2, b2):\n",
    "    #Input to hidden layer\n",
    "    z1 = np.dot(w1, X) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    #Hidden layer to output\n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    cache = {\"z1\": z1, \"a1\": a1, \"z2\": z2, \"a2\": a2}\n",
    "\n",
    "    return(a2, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bb385bc-9edb-4be1-b65b-fbdaf0648800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute loss\n",
    "\n",
    "def compute_loss(a2, y):\n",
    "    loss = -np.mean(y * np.log(a2 + 1e-9) + (1 - y) * np.log(1 - a2 + 1e-9))\n",
    "    return(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ec9d1a4-4f9f-4574-8f2d-fb2bf717730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Back propagation\n",
    "\n",
    "def back_propagation(w1, w2, cache, X, y):\n",
    "    a1 = cache[\"a1\"]\n",
    "    a2 = cache[\"a2\"]\n",
    "\n",
    "    m = X.shape[1]\n",
    "  \n",
    "    d2 = a2 - y\n",
    "    dw2 = np.dot(d2, a1.T)/ m\n",
    "    db2 = np.sum(d2, axis=1, keepdims=True) / m\n",
    "\n",
    "    d1 = np.dot(w2.T, d2) * (a1 * (1 - a1))\n",
    "    dw1 = np.dot(d1, X.T)/ m\n",
    "    db1 = np.sum(d1, axis=1, keepdims=True) / m\n",
    "\n",
    "    grads = {\"dw1\": dw1, \"db1\": db1, \"dw2\": dw2, \"db2\": db2}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0916882-2efd-4189-8a45-dfdb6bd6dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update weights and biases\n",
    "\n",
    "def update_parameters(w1, b1, w2, b2, grads):\n",
    "    dw1 = grads[\"dw1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dw2 = grads[\"dw2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    w1 -= learning_rate * dw1\n",
    "    b1 -= learning_rate * db1\n",
    "    w2 -= learning_rate * dw2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    return w1, b1, w2, b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84e835ce-9de6-48bb-acf9-8c482a45c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.7027\n",
      "Epoch 100 | Loss: 0.2240\n",
      "Epoch 200 | Loss: 0.1186\n",
      "Epoch 300 | Loss: 0.1039\n",
      "Epoch 400 | Loss: 0.0855\n",
      "Epoch 500 | Loss: 0.0776\n",
      "Epoch 600 | Loss: 0.0758\n",
      "Epoch 700 | Loss: 0.0629\n",
      "Epoch 800 | Loss: 0.0746\n",
      "Epoch 900 | Loss: 0.0477\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "\n",
    "w1, b1, w2, b2, learning_rate = initialize_parameters(784, 128, 1)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    a2, cache = forward_propagation(X_train, w1, b1, w2, b2)\n",
    "\n",
    "    loss = compute_loss(a2, y_train)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss:.4f}\")\n",
    "\n",
    "    grads = back_propagation(w1, w2, cache, X_train, y_train)\n",
    "\n",
    "    w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, grads)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448844b1-8c04-48bf-bc77-256a2a5f0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9711434150574962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/s5g5xyw936x11bzh4lf31qqc0000gn/T/ipykernel_1244/2065857832.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/ (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "#Test model\n",
    "\n",
    "a2, cache = forward_propagation(X_test, w1, b1, w2, b2)\n",
    "\n",
    "predictions = (a2 > 0.5).astype(int)  # shape: (1, m)\n",
    "correct = (predictions == y_test).astype(int)\n",
    "accuracy = np.mean(correct)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d580a25-b888-4309-b5f3-1a9c78a338f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
