{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"5c8aba09-c0e9-436d-ad41-dbe03c3327f6","_cell_guid":"43744007-a877-4874-968d-e4299d9f56e7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.007725Z","iopub.execute_input":"2025-05-13T01:12:44.008078Z","iopub.status.idle":"2025-05-13T01:12:44.015051Z","shell.execute_reply.started":"2025-05-13T01:12:44.008056Z","shell.execute_reply":"2025-05-13T01:12:44.014266Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_titanic_data(df):\n    df = df.copy()\n\n    # Encode 'Sex' as 0 (female) and 1 (male)\n    df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n\n    # Fill missing Age and Fare with mean\n    df['Age'] = df['Age'].fillna(df['Age'].mean())\n    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n\n    # Fill Embarked with mode\n    if 'Embarked' in df.columns:\n        df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n\n    # Fill Cabin with 'Unknown'\n    if 'Cabin' in df.columns:\n        df['Cabin'] = df['Cabin'].fillna('Unknown')\n\n    return df","metadata":{"_uuid":"a84436aa-5ef1-40ef-a3c5-a524f2f4fbfb","_cell_guid":"b5eebfbc-4198-4491-b01f-d280d55f4758","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.016800Z","iopub.execute_input":"2025-05-13T01:12:44.017463Z","iopub.status.idle":"2025-05-13T01:12:44.042655Z","shell.execute_reply.started":"2025-05-13T01:12:44.017434Z","shell.execute_reply":"2025-05-13T01:12:44.041616Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load training data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()\n\n# Clean data\ntrain_data_clean = preprocess_titanic_data(train_data)\n\n# Now extract features and target using NumPy\nX = train_data_clean[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].to_numpy()\ny = train_data_clean['Survived'].to_numpy()\n\n# Split training and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nX_train = X_train.T  # Now shape is (6, 891)\ny_train = y_train.reshape(1, -1)  # Make y a row vector of shape (1, 891)\n\nX_test = X_test.T  # Now shape is (6, 891)\ny_test = y_test.reshape(1, -1)  # Make y a row vector of shape (1, 891)\n\nprint(X_train.shape , X_test.shape , y_train.shape , y_test.shape)","metadata":{"_uuid":"77066a12-3d83-47e2-81fb-18ecdfa73a20","_cell_guid":"1e5d52aa-745d-456d-a6e6-3a08e43663a0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.043765Z","iopub.execute_input":"2025-05-13T01:12:44.044057Z","iopub.status.idle":"2025-05-13T01:12:44.070683Z","shell.execute_reply.started":"2025-05-13T01:12:44.044026Z","shell.execute_reply":"2025-05-13T01:12:44.069729Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load test data\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()\n\n# Clean data\ntest_data_clean = preprocess_titanic_data(test_data)\n\n# Now extract features and target using NumPy\nX_submit = test_data_clean[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].to_numpy()\n\nX_submit = X_submit.T  \nprint(X_submit.shape)","metadata":{"_uuid":"77376841-aa57-4a91-95cc-5dbdfb0bd43c","_cell_guid":"b1aadfc8-6b72-4571-96a8-958165e5d5f0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.072693Z","iopub.execute_input":"2025-05-13T01:12:44.072958Z","iopub.status.idle":"2025-05-13T01:12:44.085806Z","shell.execute_reply.started":"2025-05-13T01:12:44.072939Z","shell.execute_reply":"2025-05-13T01:12:44.084859Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define Sigmoid function and its derivative\n\ndef sigmoid(x):\n    x = np.clip(x, -500, 500) \n    return 1/ (1 + np.exp(-x))\n\ndef sigmoid_derivative(a):\n    return a * (1 - a)","metadata":{"_uuid":"aceab6a0-a5ff-42ed-90ce-e9bc2cf740e4","_cell_guid":"bea3040e-7d33-4df5-845c-5b13a5e933bb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.086552Z","iopub.execute_input":"2025-05-13T01:12:44.086888Z","iopub.status.idle":"2025-05-13T01:12:44.091668Z","shell.execute_reply.started":"2025-05-13T01:12:44.086869Z","shell.execute_reply":"2025-05-13T01:12:44.090798Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize parameters \n\ndef initialize_parameters(n_x, n_h, n_y):\n\n    w1 = np.random.randn(n_h, n_x) * 0.01\n    b1 = np.zeros((n_h, 1))\n\n    w2 = np.random.randn(n_y, n_h) * 0.01\n    b2 = np.zeros((n_y, 1))\n\n    initial_lr = 0.1\n    learning_rate = initial_lr\n\n    return(w1, b1, w2, b2, learning_rate)","metadata":{"_uuid":"22b30e46-bebd-41b6-b1e7-ca9d296ae81c","_cell_guid":"67adc270-3d05-4fb1-b526-74ff5dd8c733","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.092364Z","iopub.execute_input":"2025-05-13T01:12:44.092617Z","iopub.status.idle":"2025-05-13T01:12:44.112190Z","shell.execute_reply.started":"2025-05-13T01:12:44.092591Z","shell.execute_reply":"2025-05-13T01:12:44.111214Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Forward propagation \n\ndef forward_propagation(X, w1, b1, w2, b2):\n    #Input to hidden layer\n    z1 = np.dot(w1, X) + b1\n    a1 = sigmoid(z1)\n\n    #Hidden layer to output\n    z2 = np.dot(w2, a1) + b2\n    a2 = sigmoid(z2)\n\n    cache = {\"z1\": z1, \"a1\": a1, \"z2\": z2, \"a2\": a2}\n\n    return(a2, cache)","metadata":{"_uuid":"1fe5b42c-a28f-4d67-bbba-9f3f6d91e425","_cell_guid":"7b396e31-70b7-41fb-a134-dd48d6e06e0b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.113195Z","iopub.execute_input":"2025-05-13T01:12:44.113486Z","iopub.status.idle":"2025-05-13T01:12:44.127068Z","shell.execute_reply.started":"2025-05-13T01:12:44.113467Z","shell.execute_reply":"2025-05-13T01:12:44.126184Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute loss\n\ndef compute_loss(a2, y):\n    loss = -np.mean(y * np.log(a2 + 1e-9) + (1 - y) * np.log(1 - a2 + 1e-9))\n    return(loss)","metadata":{"_uuid":"fc796fe5-6460-421e-90eb-9ffe1b6813f8","_cell_guid":"70f433e5-5aa9-4fd4-a842-e4471326d8d1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.128090Z","iopub.execute_input":"2025-05-13T01:12:44.128384Z","iopub.status.idle":"2025-05-13T01:12:44.142006Z","shell.execute_reply.started":"2025-05-13T01:12:44.128364Z","shell.execute_reply":"2025-05-13T01:12:44.140920Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Back propagation\n\ndef back_propagation(w1, w2, cache, X, y):\n    a1 = cache[\"a1\"]\n    a2 = cache[\"a2\"]\n\n    m = X.shape[1]\n  \n    d2 = a2 - y\n    dw2 = np.dot(d2, a1.T)/ m\n    db2 = np.sum(d2, axis=1, keepdims=True) / m\n\n    d1 = np.dot(w2.T, d2) * (a1 * (1 - a1))\n    dw1 = np.dot(d1, X.T)/ m\n    db1 = np.sum(d1, axis=1, keepdims=True) / m\n\n    grads = {\"dw1\": dw1, \"db1\": db1, \"dw2\": dw2, \"db2\": db2}\n    return grads","metadata":{"_uuid":"90897d4b-7d63-4f19-8d72-b733cc214a66","_cell_guid":"1ec56196-d79b-49f7-a144-7b88761708fe","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.143725Z","iopub.execute_input":"2025-05-13T01:12:44.143957Z","iopub.status.idle":"2025-05-13T01:12:44.162912Z","shell.execute_reply.started":"2025-05-13T01:12:44.143939Z","shell.execute_reply":"2025-05-13T01:12:44.161853Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Update weights and biases\n\ndef update_parameters(w1, b1, w2, b2, grads, learning_rate):\n    dw1 = grads[\"dw1\"]\n    db1 = grads[\"db1\"]\n    dw2 = grads[\"dw2\"]\n    db2 = grads[\"db2\"]\n    \n    w1 -= learning_rate * dw1\n    b1 -= learning_rate * db1\n    w2 -= learning_rate * dw2\n    b2 -= learning_rate * db2\n    return w1, b1, w2, b2","metadata":{"_uuid":"5875495e-66e3-47cf-887e-20f7b8ba1021","_cell_guid":"2bd87668-3bf0-48fa-8889-ca1f5c3fc25d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.163870Z","iopub.execute_input":"2025-05-13T01:12:44.164167Z","iopub.status.idle":"2025-05-13T01:12:44.179788Z","shell.execute_reply.started":"2025-05-13T01:12:44.164143Z","shell.execute_reply":"2025-05-13T01:12:44.178762Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training variable\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\n\nearly_stopping_patience = 1000     # How many epochs to wait after no improvement\nbest_val_loss = float('inf')      # Best validation loss seen so far\npatience_counter = 0              # How long since we saw improvement","metadata":{"_uuid":"6472c1f3-9de1-48cd-a4ae-febd41ebcef0","_cell_guid":"e41c5c94-2bf6-4892-837e-00dbc217fce8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.180759Z","iopub.execute_input":"2025-05-13T01:12:44.181025Z","iopub.status.idle":"2025-05-13T01:12:44.196604Z","shell.execute_reply.started":"2025-05-13T01:12:44.181002Z","shell.execute_reply":"2025-05-13T01:12:44.195765Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\n\nw1, b1, w2, b2, learning_rate = initialize_parameters(6, 64, 1)\n\nfor epoch in range(15000):\n\n    # --- Forward on training set ---\n    a2_train, cache_train = forward_propagation(X_train, w1, b1, w2, b2)\n    train_loss = compute_loss(a2_train, y_train)\n    train_pred = (a2_train > 0.5).astype(int)\n    train_acc = np.mean(train_pred == y_train)\n\n    # --- Forward on validation set ---\n    a2_val, _ = forward_propagation(X_test, w1, b1, w2, b2)\n    val_loss = compute_loss(a2_val, y_test)\n    val_pred = (a2_val > 0.5).astype(int)\n    val_acc = np.mean(val_pred == y_test)\n\n    # --- Backprop + update ---\n    grads = back_propagation(w1, w2, cache_train, X_train, y_train)\n    w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, grads, learning_rate)\n\n    # --- Log metrics ---\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accuracies.append(train_acc)\n    val_accuracies.append(val_acc)\n\n    if epoch % 500 == 0:\n        print(f\"Epoch {epoch:4} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Train Acc: {train_acc:.2%} | Val Acc: {val_acc:.2%}\")\n\n    # --- Early stopping check (moved here!) ---\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        patience_counter = 0\n        best_weights = (w1.copy(), b1.copy(), w2.copy(), b2.copy())\n    else:\n        patience_counter += 1\n\n    if patience_counter > early_stopping_patience:\n        print(f\"Early stopping triggered at epoch {epoch}\")\n        break\n\n    # Learning rate decay\n    if patience_counter % 200 == 0 and patience_counter > 0:\n        learning_rate *= 0.5\n        print(f\"Reducing learning rate to {learning_rate:.6f}\")","metadata":{"_uuid":"746003e1-9df4-4d7b-8e57-c481a1678508","_cell_guid":"f6b7c0c4-2346-4c79-b520-93c00d78c95f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:44.198879Z","iopub.execute_input":"2025-05-13T01:12:44.199115Z","iopub.status.idle":"2025-05-13T01:12:55.235312Z","shell.execute_reply.started":"2025-05-13T01:12:44.199096Z","shell.execute_reply":"2025-05-13T01:12:55.234428Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = range(len(train_losses))\n\n# Loss plot\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, train_losses, label='Train Loss')\nplt.plot(epochs, val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Train vs Val Loss')\nplt.legend()\n\n# Accuracy plot\nplt.subplot(1, 2, 2)\nplt.plot(epochs, train_accuracies, label='Train Accuracy')\nplt.plot(epochs, val_accuracies, label='Val Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Train vs Val Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"f58974e3-53d0-4be2-9488-15e1d24d0f78","_cell_guid":"4bc5f46c-cbc1-4b5e-9644-5eeabaf1d60f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:55.236146Z","iopub.execute_input":"2025-05-13T01:12:55.236432Z","iopub.status.idle":"2025-05-13T01:12:55.754311Z","shell.execute_reply.started":"2025-05-13T01:12:55.236412Z","shell.execute_reply":"2025-05-13T01:12:55.753361Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Test model\n\na2, cache = forward_propagation(X_test, w1, b1, w2, b2)\n\npredictions = (a2 > 0.5).astype(int)  # shape: (1, m)\ncorrect = (predictions == y_test).astype(int)\naccuracy = np.mean(correct)\n\nprint(accuracy)","metadata":{"_uuid":"512aa1aa-0529-4a53-8f0e-c9d34382268b","_cell_guid":"a6064179-e72d-4efa-8ebf-71d7882aef39","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:18:04.519658Z","iopub.execute_input":"2025-05-13T01:18:04.519953Z","iopub.status.idle":"2025-05-13T01:18:04.526287Z","shell.execute_reply.started":"2025-05-13T01:18:04.519934Z","shell.execute_reply":"2025-05-13T01:18:04.525446Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Results for submission\n\na2_submit, cache = forward_propagation(X_submit, w1, b1, w2, b2)\n\npredictions_submit = (a2_submit > 0.5).astype(int).flatten()  # shape: (1, m)\n\nsubmission = pd.DataFrame({\n    'PassengerId': test_data_clean['PassengerId'],\n    'Survived': predictions_submit\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"_uuid":"17317e56-af2f-44e9-b59a-71c7b29ad6e6","_cell_guid":"cb347a82-938d-418d-a09d-6beba0206991","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T01:12:55.763549Z","iopub.execute_input":"2025-05-13T01:12:55.763825Z","iopub.status.idle":"2025-05-13T01:12:55.781750Z","shell.execute_reply.started":"2025-05-13T01:12:55.763806Z","shell.execute_reply":"2025-05-13T01:12:55.781031Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}